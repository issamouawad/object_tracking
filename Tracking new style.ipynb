{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: Dataset:modd, Detector:yolo, Tracker:keypoint_flow, @640x464\n",
      "Running: Dataset:graal_2, Detector:yolo, Tracker:keypoint_flow, @1032x778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\issam\\Documents\\ssd_keras\\track.py:128: RuntimeWarning: divide by zero encountered in float_scalars\n",
      "  new_width = old_width * (new_box[2]/old_box[2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import motmetrics as mm\n",
    "import imutils\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "import cv2 as cv\n",
    "import time\n",
    "from sort import *\n",
    "\n",
    "import json\n",
    "from utils import load_detections\n",
    "\n",
    "from detection import Detection\n",
    "from tracker import Tracker\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "iou_overlaps = []\n",
    "desc_dists = []\n",
    "confusion_frames = []\n",
    "confusion_tracks = []\n",
    "confusion_distances =[]\n",
    "colors = [[255,0,0],[0,255,0],[0,0,255],[0,128,128],[128,0,128],[128,128,0],[255,0,0],[0,255,0],[0,0,255],[0,128,128],[128,0,128],[128,128,0],\n",
    "         [255,0,0],[0,255,0],[0,0,255],[0,128,128],[128,0,128],[128,128,0],[255,0,0],[0,255,0],[0,0,255],[0,128,128],[128,0,128],[128,128,0],[255,0,0],[0,255,0],[0,0,255],[0,128,128],[128,0,128],[128,128,0]]\n",
    "tracking_methods=['keypoint_flow']\n",
    "#tracking_methods=['center_flow','keypoint_flow','kalman_center','kalman_corners','SORT']\n",
    "detectors = ['yolo']\n",
    "#detectors = ['ssd300','retinanet','yolo']\n",
    "#'center_fow','keypoint_flow','kalman_center','kalman_corners',\n",
    "datasets=['modd','graal_2']\n",
    "times = {}\n",
    "for dataset in datasets:\n",
    "    times[dataset]={}\n",
    "    images_input_path='../%s/'%dataset\n",
    "    image_id_prefix= dataset\n",
    "    frame_width=1032\n",
    "    frame_height=778\n",
    "    if(dataset=='venc'):\n",
    "        frame_width = 1280\n",
    "        frame_height = 960\n",
    "    if(dataset=='modd'):\n",
    "        frame_width=640\n",
    "        frame_height=464\n",
    "    if(dataset=='mot_1'):\n",
    "        frame_width=768\n",
    "        frame_height=576\n",
    "    iou_threshold = 0.1\n",
    "    for detector in detectors:\n",
    "        times[dataset][detector] = {}\n",
    "        boat_class=8\n",
    "        min_conf=0.6\n",
    "        if(detector=='ssd300'):\n",
    "            boat_class=4\n",
    "            min_conf=0.5\n",
    "        if(detector=='def'):\n",
    "            boat_class=1\n",
    "        \n",
    "\n",
    "        path = '%s/%s_videos'%(detector,image_id_prefix)\n",
    "        detections = load_detections(image_id_prefix,detector,boat_class,min_conf)\n",
    "        for tracking_method in tracking_methods:\n",
    "            times[dataset][detector][tracking_method] = []\n",
    "            video_output_path='%s/%s.avi'%(path,tracking_method)\n",
    "            json_output_path='%s/%s.json'%(path,tracking_method)\n",
    "            out_tracking = cv.VideoWriter(video_output_path,cv.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "            frameCount =0\n",
    "            no_tracking_res = [] \n",
    "            tracking_res = []\n",
    "            kalman_trackers=[]\n",
    "            # initialize the first frame in the video stream\n",
    "            frameCount =0\n",
    "            step_up = 0.1\n",
    "            step_down = 0.2\n",
    "            print('Running: Dataset:%s, Detector:%s, Tracker:%s, @%dx%d'%(dataset,detector,tracking_method,frame_width,frame_height))\n",
    "            preds = []\n",
    "            tracks=[]\n",
    "            started = False\n",
    "            multiplier=0\n",
    "            cc=0\n",
    "            prev_frame=None\n",
    "            \n",
    "            total_frames=641\n",
    "            if(tracking_method=='SORT'):\n",
    "                mot_tracker = Sort()\n",
    "            else:\n",
    "                tracker_wrapper = Tracker(tracking_method)\n",
    "                tracker_wrapper.frame_width = frame_width\n",
    "                tracker_wrapper.frame_height = frame_height\n",
    "                if(dataset=='modd'):\n",
    "                    tracker_wrapper.A = np.array([int(frame_width/2),int(frame_height/2)])\n",
    "                    tracker_wrapper.B = np.array([int(frame_width/5),int(frame_height-1)])\n",
    "                    tracker_wrapper.C= np.array([int(4*frame_width/5),frame_height-1])\n",
    "                elif(dataset=='graal_1' or dataset == 'graal_2'):\n",
    "                    tracker_wrapper.A = np.array([int(frame_width/2),int(frame_height/2)])\n",
    "                    tracker_wrapper.B = np.array([int(frame_width/5),int(frame_height-1)])\n",
    "                    tracker_wrapper.C= np.array([int(4*frame_width/5),frame_height-1])\n",
    "            while frameCount<total_frames:\n",
    "                \n",
    "                # grab the current frame and initialize the occupied/unoccupied\n",
    "                # text\n",
    "                frame = cv.imread('%s%s.jpg'%(images_input_path,str(frameCount+1).zfill(5)))\n",
    "                \n",
    "                \n",
    "                # if the frame could not be grabbed, then we have reached the end\n",
    "                # of the video\n",
    "                if frame is None:\n",
    "                    break\n",
    "\n",
    "                if(frameCount<0):\n",
    "                    continue\n",
    "\n",
    "                preds = []\n",
    "                if '%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5)) in detections:\n",
    "\n",
    "                    for box in detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]:\n",
    "\n",
    "                        if(box.conf<min_conf):\n",
    "\n",
    "                            continue\n",
    "                        if(tracking_method=='SORT'):\n",
    "                            temp_pred = box[2:]\n",
    "\n",
    "                            temp_pred = np.insert(temp_pred,4,box[1])\n",
    "\n",
    "                            preds.append(temp_pred)\n",
    "                        else:\n",
    "                            preds = detections['%s/%s.jpg'%(image_id_prefix,str(frameCount+1).zfill(5))]\n",
    "                        \n",
    "                start= time.time()\n",
    "                if(tracking_method=='SORT'):\n",
    "\n",
    "                    preds = np.asarray(preds)\n",
    "                    trackers = mot_tracker.update(preds)\n",
    "                    to_display = []\n",
    "                    for itrk,tracker in enumerate(trackers):\n",
    "                        to_display.append([tracker[4],boat_class,preds[itrk][4],tracker[0],tracker[1],tracker[2],tracker[3]])\n",
    "                else:   \n",
    "                    \n",
    "                    tracker_wrapper.track(preds,frame,prev_frame)\n",
    "                    \n",
    "                    \n",
    "                    to_display = tracker_wrapper.get_display_tracks()\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        #print(acc.mot_events.loc[frameId])\n",
    "               \n",
    "                col_points = tracker_wrapper.get_collision_points()\n",
    "                if(len(col_points)>0):\n",
    "                    col = [0,0,255]\n",
    "                    cv.putText(frame,'Collision detected!', (20, 20),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "                \n",
    "                else:\n",
    "                    col = [0,255,255]\n",
    "                cv.line(frame,(tracker_wrapper.A[0],tracker_wrapper.A[1]),(tracker_wrapper.B[0],tracker_wrapper.B[1]),col,1)\n",
    "                cv.line(frame,(tracker_wrapper.A[0],tracker_wrapper.A[1]),(tracker_wrapper.C[0],tracker_wrapper.C[1]),col,1)\n",
    "                \n",
    "                \n",
    "               \n",
    "                \n",
    "                for p in col_points:\n",
    "                    cv.circle(frame,(int(p[0]),int(p[1])),8,(0,0,255),1)\n",
    "                i=0\n",
    "                for box in to_display:\n",
    "                    \n",
    "                # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "                    if(box.conf<0.5):\n",
    "                        i+=1\n",
    "                        continue\n",
    "                    xmin = int(box.xmin)\n",
    "                    ymin = int(box.ymin)\n",
    "                    xmax =int(box.xmax)\n",
    "                    ymax =int(box.ymax)\n",
    "                    \n",
    "                    cv.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), colors[int(box.track_id)%len(colors)], 2)\n",
    "                    p1 = box.center()\n",
    "                    p2 = box.center()\n",
    "                    p2[0] += box.offset[0]*2\n",
    "                    p2[1] += box.offset[1]*15\n",
    "                    cv.arrowedLine(frame,(int(p1[0]),int(p1[1])),(int(p2[0]),int(p2[1])),(0,0,255),2)\n",
    "                    if(tracking_method=='kalman_center'):\n",
    "                        \n",
    "                        cv.circle(frame,(int(predictions[i][0][0]),int(predictions[i][1][0])),5,(255,0,0),2)\n",
    "                    #if(tracking_method=='kalman_corners'):\n",
    "                        #cv.circle(frame,(int(predictions[i][0][0]),int(predictions[i][1][0])),5,(255,0,0),2)\n",
    "                        #cv.circle(frame,(int(predictions[i][2][0]),int(predictions[i][3][0])),5,(255,0,0),2)\n",
    "                    cv.putText(frame,'{:.2f}'.format( box.conf), (xmin, ymin),cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                    \n",
    "\n",
    "                    tracking_res.append({\"image_id\" : frameCount+1, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)], \"score\" : np.minimum(1.0,box.conf),\"id\":box.track_id})\n",
    "                    #f.write(\"graal_2/%s.jpg,%s,%d,%f,%f,%f,%f,%f\\n\"%(str(frameCount+1).zfill(5),classes[int(box[1])],box[1],box[2],xmin,ymin,xmax,ymax))\n",
    "                    i+=1\n",
    "                    times[dataset][detector][tracking_method].append(time.time()-start)\n",
    "                \n",
    "                out_tracking.write(frame)\n",
    "                #cv.imwrite('debug_frames/%s.jpg'%str(frameCount+1),frame)\n",
    "                frameCount+=1\n",
    "                prev_frame=frame\n",
    "                flow = None\n",
    "            # cleanup the camera and close any open windows\n",
    "\n",
    "            out_tracking.release()\n",
    "            \n",
    "\n",
    "\n",
    "            with open(json_output_path, 'w') as outfile:  \n",
    "                json.dump(tracking_res, outfile)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06495558330789208\n"
     ]
    }
   ],
   "source": [
    "print(np.average(times['graal_1']['yolo']['keypoint_flow']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import PointInTriangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([int(frame_width/2),int(frame_height/2)])\n",
    "B = np.array([int(frame_width/5),int(frame_height-1)])\n",
    "C= np.array([int(4*frame_width/5),frame_height-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[516 389] [206 777] [825 777]\n"
     ]
    }
   ],
   "source": [
    "print(A,B,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420.5658914728683\n"
     ]
    }
   ],
   "source": [
    "P = np.array([700,480])\n",
    "print(applyFormula2(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.pointPolygonTest??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFormula(p):\n",
    "    return (5*frame_height *p[0])/frame_width + 3*p[1] -4*frame_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFormula2(p):\n",
    "    return (5*frame_height *p[0])/frame_width - 3*p[1] -frame_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
