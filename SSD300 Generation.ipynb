{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "img_height = 464\n",
    "img_width = 640\n",
    "# 1: Build the Keras model\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, 3),\n",
    "                n_classes=20,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], # The scales for MS COCO are [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=[8, 16, 32, 64, 100, 300],\n",
    "                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                clip_boxes=False,\n",
    "                variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                normalize_coords=True,\n",
    "                subtract_mean=[123, 117, 104],\n",
    "                swap_channels=[2, 1, 0],\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400)\n",
    "\n",
    "# 2: Load the trained weights into the model.\n",
    "\n",
    "# TODO: Set the path of the trained weights.\n",
    "weights_path = 'VGG_VOC0712Plus_SSD_300x300_ft_iter_160000.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "# 3: Compile the model so that Keras won't complain the next time you load it.\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "colors = plt.cm.hsv(np.linspace(0, 1, 21)).tolist()\n",
    "classes = ['background',\n",
    "           'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "           'bottle', 'bus', 'car', 'cat',\n",
    "           'chair', 'cow', 'diningtable', 'dog',\n",
    "           'horse', 'motorbike', 'person', 'pottedplant',\n",
    "           'sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "464\n",
      "643.2742085456848\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "frameCount =0\n",
    "inferencesCount=0\n",
    "inferencesCountFinal=0\n",
    "framesCountFinal=0\n",
    "frame_width = int(vs.get(3))\n",
    "frame_height = int(vs.get(4))\n",
    "print(frame_width)\n",
    "print(frame_height)\n",
    "out = cv2.VideoWriter('full_baseline_img.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 30, (frame_width,frame_height))\n",
    "started = False\n",
    "# your code\n",
    "no_tracking_res= []\n",
    "frames=glob.glob('../modd/*.jpg')\n",
    "for path in frames:\n",
    "    # grab the current frame and initialize the occupied/unoccupied\n",
    "    # text\n",
    "    \n",
    "    \n",
    " \n",
    "    # if the frame could not be grabbed, then we have reached the end\n",
    "    # of the video\n",
    "    \n",
    "    frameCount+=1\n",
    "    if(frameCount<0):\n",
    "        continue\n",
    "    elif started==False:\n",
    "        start_time = time.time()\n",
    "        started=True\n",
    "    # resize the frame, convert it to grayscale, and blur it\n",
    "    \n",
    "    img = image.load_img(path, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "    input_images = []\n",
    "    \n",
    "    input_images.append(img)\n",
    "    input_images = np.array(input_images)\n",
    "    y_pred = model.predict(input_images)\n",
    "    \n",
    "    confidence_threshold = 0.4\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    # loop over the contours\n",
    "\n",
    "    for box in y_pred_thresh[0]:\n",
    "    # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "        if(box[0]!=4):\n",
    "            continue\n",
    "        xmin = int(box[-4] * frame.shape[1] / img_width)\n",
    "        ymin = int(box[-3] * frame.shape[0] / img_height)\n",
    "        xmax =int(box[-2] * frame.shape[1] / img_width)\n",
    "        ymax =int(box[-1] * frame.shape[0] / img_height)\n",
    "        cv2.rectangle(frame, (int(xmin), int(ymin)), (int(xmax),int(ymax)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame,'{}: {:.2f}'.format(classes[int(box[0])], box[1]), (xmin, ymin),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "        \n",
    "        no_tracking_res.append({\"image_id\" : frameCount, \"category_id\" : 1, \"bbox\" : [float(xmin),float(ymin),float(xmax-xmin),float(ymax-ymin)], \"score\" : int(box[1])})\n",
    "   \n",
    "    out.write(frame)\n",
    "# cleanup the camera and close any open windows\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "out.release()\n",
    "with open('full_baseline_img.json', 'w') as outfile:  \n",
    "    json.dump(no_tracking_res, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "464\n",
      "../modd\\00001.jpg\n",
      "1\n",
      "../modd\\00002.jpg\n",
      "2\n",
      "../modd\\00003.jpg\n",
      "3\n",
      "../modd\\00004.jpg\n",
      "4\n",
      "../modd\\00005.jpg\n",
      "5\n",
      "../modd\\00006.jpg\n",
      "6\n",
      "../modd\\00007.jpg\n",
      "7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0729b3df0c16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0minput_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mconfidence_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "#vs = cv2.VideoCapture('../modd.avi')\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "frameCount =0\n",
    "inferencesCount=0\n",
    "inferencesCountFinal=0\n",
    "framesCountFinal=0\n",
    "frame_width = 640\n",
    "frame_height = 464\n",
    "print(frame_width)\n",
    "print(frame_height)\n",
    "started = False\n",
    "# your code\n",
    "no_tracking_res= []\n",
    "frames=glob.glob('../modd/*.jpg')\n",
    "f = open(\"modd_full_image_ssd300.txt\",\"a\")\n",
    "\n",
    "for filePath in frames:\n",
    "    print(filePath)\n",
    "    frameCount+=1\n",
    "    if(frameCount<0):\n",
    "        continue\n",
    "    if(frameCount>100):\n",
    "        break\n",
    "    print(frameCount)\n",
    "    img = image.load_img(filePath, target_size=(img_height, img_width))\n",
    "    \n",
    "    img = image.img_to_array(img)\n",
    "    input_images = []\n",
    "    \n",
    "    input_images.append(img)\n",
    "    input_images = np.array(input_images)\n",
    "    \n",
    "    y_pred = model.predict(input_images)\n",
    "    \n",
    "    confidence_threshold = 0.3\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    # loop over the contours\n",
    "\n",
    "    for box in y_pred_thresh[0]:\n",
    "    # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "        \n",
    "        xmin = int(box[-4] * frame_width / img_width)\n",
    "        ymin = int(box[-3] * frame_height / img_height)\n",
    "        xmax =int(box[-2] * frame_width / img_width)\n",
    "        ymax =int(box[-1] * frame_height / img_height)\n",
    "        \n",
    "        f.write(\"modd/%s.jpg,%s,%d,%f,%f,%f,%f,%f\\n\"%(str(frameCount).zfill(5),classes[int(box[0])],box[0],box[1],xmin,ymin,xmax,ymax))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"ssd_300_baseline_modd_vid.txt\",\"r\")\n",
    "tracking_res = []\n",
    "line = f.readline()\n",
    "while(line):\n",
    "    comps = line.split(',')\n",
    "    if(comps[2]=='4'):\n",
    "        xmin = float(comps[4])\n",
    "        ymin = float(comps[5])\n",
    "        xmax = float(comps[6])\n",
    "        ymax = float(comps[7])\n",
    "        tracking_res.append({\"image_id\" : int(comps[0][5:10]), \"category_id\" : 1, \"bbox\" : [xmin,ymin,(xmax-xmin),(ymax-ymin)], \"score\" : float(comps[3])})\n",
    "    line = f.readline()\n",
    "with open('ssd300_baseline_modd_vid.json', 'w') as outfile:  \n",
    "    json.dump(tracking_res, outfile)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "464\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import time\n",
    "import json\n",
    "#vs = cv2.VideoCapture('../modd.avi')\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "frameCount =0\n",
    "vs = cv2.VideoCapture('../modd.avi')\n",
    "inferencesCount=0\n",
    "inferencesCountFinal=0\n",
    "framesCountFinal=0\n",
    "frame_width = int(vs.get(3))\n",
    "frame_height = int(vs.get(4))\n",
    "print(frame_width)\n",
    "print(frame_height)\n",
    "started = False\n",
    "# your code\n",
    "no_tracking_res= []\n",
    "\n",
    "f = open(\"ssd_300_baseline_modd_vid.txt\",\"a\")\n",
    "\n",
    "while frameCount<641:\n",
    "    \n",
    "    frameCount+=1\n",
    "  \n",
    "    \n",
    "    frame = vs.read()[1]\n",
    "    \n",
    "    cv2.imwrite('temp.jpg',frame)\n",
    "    img = image.load_img('temp.jpg', target_size=(img_height, img_width))\n",
    "    \n",
    "    img = image.img_to_array(img)\n",
    "    input_images = []\n",
    "    \n",
    "    input_images.append(img)\n",
    "    input_images = np.array(input_images)\n",
    "    \n",
    "    y_pred = model.predict(input_images)\n",
    "    \n",
    "    confidence_threshold = 0.1\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    # loop over the contours\n",
    "\n",
    "    for box in y_pred_thresh[0]:\n",
    "    # Transform the predicted bounding boxes for the 512x512 image to the original image dimensions.\n",
    "        \n",
    "        xmin = int(box[-4] * frame_width / img_width)\n",
    "        ymin = int(box[-3] * frame_height / img_height)\n",
    "        xmax =int(box[-2] * frame_width / img_width)\n",
    "        ymax =int(box[-1] * frame_height / img_height)\n",
    "        \n",
    "        f.write(\"modd/%s.jpg,%s,%d,%f,%f,%f,%f,%f\\n\"%(str(frameCount).zfill(5),classes[int(box[0])],box[0],box[1],xmin,ymin,xmax,ymax))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
