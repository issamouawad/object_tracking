{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2 as cv\n",
    "from bounding_box_utils.bounding_box_utils import iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_photo(dataset,detector,image_id,gts,det,state):\n",
    "    img = cv.imread('../%s/%s.jpg'%(dataset,str(image_id).zfill(5)))\n",
    "    \n",
    "    i =1\n",
    "    for s in state:\n",
    "        cv.putText(img,s, (30,i*70),cv.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 6)\n",
    "        i+=1\n",
    "    for gt in gts:\n",
    "        \n",
    "    \n",
    "        cv.rectangle(img, (int(gt[0]), int(gt[1])), (int(gt[2]+gt[0]),int(gt[1]+gt[3])), (255,0,0), 2)\n",
    "    if (len(det)>0):\n",
    "        for dd in det:\n",
    "            \n",
    "            cv.rectangle(img, (int(dd[0]), int(dd[1])), (int(dd[2]+dd[0] ),int(dd[3]+dd[1])), (0,255,0), 2)\n",
    "    cv.imwrite('errors/%s/%s.jpg'%(dataset,str(image_id).zfill(5)),img)\n",
    "def get_summary_dataset_mot(gt_path,dataset,detector,tracker):\n",
    "    gt={}\n",
    "    json_ground_trth = \"../%s.txt\"%gt_path\n",
    "    gt_file = open(json_ground_trth,\"r\")\n",
    "    line = gt_file.readline()\n",
    "    while(line):\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        comps = line.split(\",\")\n",
    "        image_id = int(comps[0])\n",
    "        if(image_id not in gt):\n",
    "            gt[image_id]= []\n",
    "        gt[image_id].append(np.array([int(comps[1]),float(comps[2]),float(comps[3]),float(comps[4]),float(comps[5])],np.float32))\n",
    "        line = gt_file.readline()\n",
    "    gt_file.close()\n",
    "            \n",
    "    json_results = \"%s/%s/%s.json\"%(dataset,detector,tracker)\n",
    "    dets = {}\n",
    "    with open(json_results) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "        for box in data:\n",
    "            image_id=box['image_id']\n",
    "            bbox = box['bbox']\n",
    "            if(image_id in dets):\n",
    "                l = list(map(float, bbox))\n",
    "                l.append(box['id'])\n",
    "                dets[image_id].append(l)\n",
    "                \n",
    "            else:\n",
    "                dets[image_id]=[]\n",
    "                l = list(map(float, bbox))\n",
    "                l.append(box['id'])\n",
    "                dets[image_id].append(l)\n",
    "                \n",
    "    \n",
    "    acc = mm.MOTAccumulator(auto_id=True)\n",
    "    \n",
    "    for key, value in gt.items():\n",
    "        if(key in dets):\n",
    "            track_boxes = [v[0:4] for v in dets[key]]\n",
    "            ids = [d[4] for d in dets[key]]\n",
    "        else:\n",
    "            track_boxes = []\n",
    "            ids=[]\n",
    "        \n",
    "        gt_boxes = [vv[1:] for vv in value]\n",
    "        \n",
    "        ff = mm.distances.iou_matrix(track_boxes,gt_boxes, max_iou=0.5)\n",
    "        \n",
    "            \n",
    "        frameId =acc.update(\n",
    "        [t[0] for t in value] ,                 # Ground truth objects in this frame\n",
    "        ids,                  # Detector hypotheses in this frame\n",
    "\n",
    "                 ff)\n",
    "        \n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute(acc, metrics=['num_frames', 'num_false_positives','num_misses','num_switches','num_matches','mostly_tracked','partially_tracked','mostly_lost','precision','recall','mota', 'motp','obj_frequencies','pred_frequencies','num_detections','num_objects'], name='acc')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_summary_dataset(gt_path,dataset,detector,tracker,input_path):\n",
    "    gt={}\n",
    "    json_ground_trth = \"../%s.json\"%gt_path\n",
    "    with open(json_ground_trth) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "        for box in data['annotations']:\n",
    "            image_id=box['image_id']\n",
    "            box_id = box['id']\n",
    "            bbox = box['bbox']\n",
    "            if(image_id not in gt):\n",
    "                gt[image_id]= []\n",
    "            gt[image_id].append([float(bbox[0]),float(bbox[1]),float(bbox[2]),float(bbox[3]),int(box_id)])\n",
    "            \n",
    "        \n",
    "    json_results = \"%s/%s/%s.json\"%(detector,dataset,tracker)\n",
    "    dets = {}\n",
    "    with open(json_results) as json_file:  \n",
    "        data = json.load(json_file)\n",
    "        for box in data:\n",
    "            image_id=box['image_id']\n",
    "           \n",
    "            bbox = box['bbox']\n",
    "            if(image_id in dets):\n",
    "                \n",
    "                \n",
    "                dets[image_id].append([bbox[0],bbox[1],bbox[2],bbox[3],box['id']])\n",
    "                \n",
    "            else:\n",
    "                dets[image_id]=[]\n",
    "                \n",
    "               \n",
    "                dets[image_id].append([bbox[0],bbox[1],bbox[2],bbox[3],box['id']])\n",
    "    acc = mm.MOTAccumulator(auto_id=True)\n",
    "    \n",
    "    for key, value in gt.items():\n",
    "        \n",
    "        if(key in dets):\n",
    "            track_boxes = [v[0:4] for v in dets[key]]\n",
    "            ids = [d[4] for d in dets[key]]\n",
    "        else:\n",
    "            track_boxes = []\n",
    "            ids=[]\n",
    "        value_boxes = [g[0:4] for g in value]\n",
    "        ff = mm.distances.iou_matrix(track_boxes, value_boxes, max_iou=0.5)\n",
    "        \n",
    "            \n",
    "        frameId =acc.update(\n",
    "        np.arange(len(value_boxes)),                 # Ground truth objects in this frame\n",
    "        ids,                  # Detector hypotheses in this frame\n",
    "\n",
    "                 ff)\n",
    "        \n",
    "        i=-1\n",
    "        det_index = -1;\n",
    "        words = [d for d in acc.mot_events.loc[frameId]['Type']]\n",
    "        \n",
    "        #save_photo(input_path,detector,key,value_boxes,track_boxes,words)\n",
    "            \n",
    "       \n",
    "    mh = mm.metrics.create()\n",
    "    summary = mh.compute(acc, metrics=['num_frames', 'num_false_positives','num_misses','num_switches','num_matches','mostly_tracked','partially_tracked','mostly_lost','precision','recall','mota', 'motp','obj_frequencies','pred_frequencies','num_detections','num_objects'], name='acc')\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "#ground_truth_file_names = ['data','data_graal1_rev','data_graal2']\n",
    "#dataset_output_path = ['modd_videos','graal_1_videos','graal_2_videos']\n",
    "ground_truth_file_names = ['data','data_graal1_rev','data_graal2']\n",
    "dataset_image_path = ['modd','graal_1','graal_2']\n",
    "dataset_output_path = ['modd_videos','graal_1_videos','graal_2_videos']\n",
    "for i in range(len(ground_truth_file_names)):\n",
    "    \n",
    "    with open('yolo/%s/mot_results.csv'%(dataset_output_path[i]), 'w', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "        row = ['Frames','Tot Objects','Tot detections','TP','FN','FP','Track Switches','Precision','Recall','MOTA','MOTP']\n",
    "        writer.writerow(row)\n",
    "        for det in ['yolo']:\n",
    "            for track in ['keypoint_flow','kalman_corners']:\n",
    "                summary = get_summary_dataset(ground_truth_file_names[i],dataset_output_path[i],det,track,dataset_image_path[i])\n",
    "                \n",
    "                row = []\n",
    "                row.append(summary['num_frames'][0])\n",
    "                row.append(summary['num_objects'][0])\n",
    "                row.append(summary['num_detections'][0])\n",
    "                row.append(summary['num_matches'][0])\n",
    "                row.append(summary['num_misses'][0])\n",
    "                row.append(summary['num_false_positives'][0])\n",
    "                row.append(summary['num_switches'][0])\n",
    "                row.append(summary['precision'][0])\n",
    "                row.append(summary['recall'][0])\n",
    "                row.append(summary['mota'][0])\n",
    "                row.append(summary['motp'][0])\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary = get_summary_dataset_mot('mot_gt','mot_1_videos','def','SORT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frames', 'Tot Objects', 'Tot detections', 'TP', 'FN', 'FP', 'Track Switches', 'Precision', 'Recall', 'MOTA', 'MOTP']\n",
      "[795, 4650, 2066, 1695, 2584, 893, 371, 0.6982088543426833, 0.4443010752688172, 0.1724731182795699, 0.3212888721092702]\n"
     ]
    }
   ],
   "source": [
    "row = ['Frames','Tot Objects','Tot detections','TP','FN','FP','Track Switches','Precision','Recall','MOTA','MOTP']\n",
    "print(row)\n",
    "row = []\n",
    "row.append(summary['num_frames'][0])\n",
    "row.append(summary['num_objects'][0])\n",
    "row.append(summary['num_detections'][0])\n",
    "row.append(summary['num_matches'][0])\n",
    "row.append(summary['num_misses'][0])\n",
    "row.append(summary['num_false_positives'][0])\n",
    "row.append(summary['num_switches'][0])\n",
    "row.append(summary['precision'][0])\n",
    "row.append(summary['recall'][0])\n",
    "row.append(summary['mota'][0])\n",
    "row.append(summary['motp'][0])\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.putText??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
